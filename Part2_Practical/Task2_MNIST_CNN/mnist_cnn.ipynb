{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 2: MNIST Handwritten Digits Classification using CNN\n",
        "\n",
        "## Objective\n",
        "Build a Convolutional Neural Network (CNN) to classify handwritten digits from the MNIST dataset and achieve >95% test accuracy.\n",
        "\n",
        "## Goals\n",
        "1. Load and preprocess MNIST dataset\n",
        "2. Build a CNN model architecture\n",
        "3. Train the model with proper validation\n",
        "4. Achieve >95% test accuracy\n",
        "5. Visualize model predictions on sample images\n",
        "6. Analyze model performance and architecture\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Set style for better visualizations\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Keras version:\", keras.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load and Explore MNIST Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "print(\"Dataset shapes:\")\n",
        "print(f\"Training images: {x_train.shape}\")\n",
        "print(f\"Training labels: {y_train.shape}\")\n",
        "print(f\"Test images: {x_test.shape}\")\n",
        "print(f\"Test labels: {y_test.shape}\")\n",
        "\n",
        "print(f\"\\nData types:\")\n",
        "print(f\"Images dtype: {x_train.dtype}\")\n",
        "print(f\"Labels dtype: {y_train.dtype}\")\n",
        "\n",
        "print(f\"\\nValue ranges:\")\n",
        "print(f\"Image pixel range: {x_train.min()} to {x_train.max()}\")\n",
        "print(f\"Label range: {y_train.min()} to {y_train.max()}\")\n",
        "\n",
        "print(f\"\\nUnique classes: {np.unique(y_train)}\")\n",
        "\n",
        "# Visualize some sample images\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
        "for i in range(10):\n",
        "    row = i // 5\n",
        "    col = i % 5\n",
        "    axes[row, col].imshow(x_train[i], cmap='gray')\n",
        "    axes[row, col].set_title(f'Label: {y_train[i]}')\n",
        "    axes[row, col].axis('off')\n",
        "plt.suptitle('Sample MNIST Images', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Class distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(y_train, bins=10, alpha=0.7, label='Training', color='blue')\n",
        "plt.hist(y_test, bins=10, alpha=0.7, label='Test', color='red')\n",
        "plt.xlabel('Digit Class')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Class Distribution')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "plt.bar(unique, counts, alpha=0.7, color='skyblue')\n",
        "plt.xlabel('Digit Class')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Training Set Class Distribution')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize pixel values to [0, 1] range\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Reshape images to include channel dimension (28, 28, 1)\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# Convert labels to categorical (one-hot encoding)\n",
        "y_train_cat = keras.utils.to_categorical(y_train, 10)\n",
        "y_test_cat = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "print(\"After preprocessing:\")\n",
        "print(f\"Training images shape: {x_train.shape}\")\n",
        "print(f\"Test images shape: {x_test.shape}\")\n",
        "print(f\"Training labels shape: {y_train_cat.shape}\")\n",
        "print(f\"Test labels shape: {y_test_cat.shape}\")\n",
        "\n",
        "print(f\"\\nNormalized pixel range: {x_train.min():.3f} to {x_train.max():.3f}\")\n",
        "\n",
        "# Verify one-hot encoding\n",
        "print(f\"\\nSample one-hot encoded labels:\")\n",
        "print(f\"Original: {y_train[:5]}\")\n",
        "print(f\"One-hot: {y_train_cat[:5]}\")\n",
        "\n",
        "# Create validation split from training data\n",
        "x_val = x_train[:10000]\n",
        "y_val = y_train_cat[:10000]\n",
        "x_train = x_train[10000:]\n",
        "y_train_cat = y_train_cat[10000:]\n",
        "\n",
        "print(f\"\\nAfter validation split:\")\n",
        "print(f\"Training: {x_train.shape[0]} samples\")\n",
        "print(f\"Validation: {x_val.shape[0]} samples\")\n",
        "print(f\"Test: {x_test.shape[0]} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Build CNN Model Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build CNN model\n",
        "model = keras.Sequential([\n",
        "    # First Convolutional Block\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "    \n",
        "    # Second Convolutional Block\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "    \n",
        "    # Third Convolutional Block\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.25),\n",
        "    \n",
        "    # Dense Layers\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Display model architecture\n",
        "model.summary()\n",
        "\n",
        "# Calculate total parameters\n",
        "total_params = model.count_params()\n",
        "print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "\n",
        "# Visualize model architecture\n",
        "keras.utils.plot_model(model, to_file='mnist_cnn_architecture.png', \n",
        "                      show_shapes=True, show_layer_names=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Train the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define callbacks for better training\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=5,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "print(\"Starting training...\")\n",
        "history = model.fit(\n",
        "    x_train, y_train_cat,\n",
        "    batch_size=128,\n",
        "    epochs=50,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nTraining completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Evaluate Model Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test_cat, verbose=0)\n",
        "\n",
        "print(\"=== MODEL EVALUATION ===\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "\n",
        "# Check if we achieved the target accuracy\n",
        "target_accuracy = 0.95\n",
        "if test_accuracy >= target_accuracy:\n",
        "    print(f\"âœ… SUCCESS: Achieved target accuracy of {target_accuracy*100:.1f}%!\")\n",
        "else:\n",
        "    print(f\"âŒ Target not met: Need {target_accuracy*100:.1f}%, got {test_accuracy*100:.2f}%\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\n=== CLASSIFICATION REPORT ===\")\n",
        "print(classification_report(y_test, y_pred_classes, \n",
        "                          target_names=[str(i) for i in range(10)]))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=range(10), yticklabels=range(10))\n",
        "plt.title('Confusion Matrix - MNIST CNN')\n",
        "plt.xlabel('Predicted Digit')\n",
        "plt.ylabel('Actual Digit')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Visualize Training History and Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Plot accuracy\n",
        "axes[0].plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
        "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
        "axes[0].set_title('Model Accuracy')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True)\n",
        "\n",
        "# Plot loss\n",
        "axes[1].plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "axes[1].plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
        "axes[1].set_title('Model Loss')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Loss')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize predictions on sample images\n",
        "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
        "sample_indices = np.random.choice(len(x_test), 15, replace=False)\n",
        "\n",
        "for i, idx in enumerate(sample_indices):\n",
        "    row = i // 5\n",
        "    col = i % 5\n",
        "    \n",
        "    # Display image\n",
        "    axes[row, col].imshow(x_test[idx].reshape(28, 28), cmap='gray')\n",
        "    \n",
        "    # Get prediction\n",
        "    true_label = y_test[idx]\n",
        "    pred_label = y_pred_classes[idx]\n",
        "    confidence = y_pred[idx][pred_label]\n",
        "    \n",
        "    # Color code: green for correct, red for incorrect\n",
        "    color = 'green' if true_label == pred_label else 'red'\n",
        "    \n",
        "    axes[row, col].set_title(f'True: {true_label}\\\\nPred: {pred_label}\\\\nConf: {confidence:.3f}', \n",
        "                            color=color, fontsize=10)\n",
        "    axes[row, col].axis('off')\n",
        "\n",
        "plt.suptitle('Sample Predictions (Green=Correct, Red=Incorrect)', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Analyze misclassified examples\n",
        "misclassified = np.where(y_test != y_pred_classes)[0]\n",
        "print(f\"\\nMisclassified examples: {len(misclassified)} out of {len(y_test)}\")\n",
        "print(f\"Misclassification rate: {len(misclassified)/len(y_test)*100:.2f}%\")\n",
        "\n",
        "if len(misclassified) > 0:\n",
        "    print(\"\\nSample misclassified images:\")\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "    for i in range(min(10, len(misclassified))):\n",
        "        row = i // 5\n",
        "        col = i % 5\n",
        "        idx = misclassified[i]\n",
        "        \n",
        "        axes[row, col].imshow(x_test[idx].reshape(28, 28), cmap='gray')\n",
        "        axes[row, col].set_title(f'True: {y_test[idx]}, Pred: {y_pred_classes[idx]}', \n",
        "                                color='red', fontsize=10)\n",
        "        axes[row, col].axis('off')\n",
        "    \n",
        "    plt.suptitle('Misclassified Examples', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Model Analysis and Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== FINAL SUMMARY ===\")\n",
        "print(f\"\\nðŸŽ¯ Model Performance:\")\n",
        "print(f\"   â€¢ Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "print(f\"   â€¢ Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "print(f\"\\nðŸ—ï¸ Model Architecture:\")\n",
        "print(f\"   â€¢ Total Parameters: {total_params:,}\")\n",
        "print(f\"   â€¢ Convolutional Layers: 5\")\n",
        "print(f\"   â€¢ Dense Layers: 3\")\n",
        "print(f\"   â€¢ Regularization: BatchNorm + Dropout\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Training Results:\")\n",
        "print(f\"   â€¢ Final Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
        "print(f\"   â€¢ Final Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
        "print(f\"   â€¢ Epochs Trained: {len(history.history['accuracy'])}\")\n",
        "\n",
        "print(f\"\\nâœ… Task 2 Complete: MNIST CNN Classification\")\n",
        "print(f\"   All objectives achieved:\")\n",
        "print(f\"   âœ“ MNIST dataset loaded and preprocessed\")\n",
        "print(f\"   âœ“ CNN model architecture built\")\n",
        "print(f\"   âœ“ Model trained with validation\")\n",
        "print(f\"   âœ“ Target accuracy of >95% achieved: {test_accuracy*100:.2f}%\")\n",
        "print(f\"   âœ“ Model predictions visualized on sample images\")\n",
        "print(f\"   âœ“ Performance analyzed and interpreted\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

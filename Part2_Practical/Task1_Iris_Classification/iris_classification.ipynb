{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 1: Iris Species Classification using Scikit-learn\n",
        "\n",
        "## Objective\n",
        "Build a decision tree classifier to predict iris species using the famous Iris dataset.\n",
        "\n",
        "## Goals\n",
        "1. Preprocess the data (handle missing values, encode labels)\n",
        "2. Train a decision tree classifier\n",
        "3. Evaluate using accuracy, precision, and recall\n",
        "4. Visualize the decision tree and results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better visualizations\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load and Explore the Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# Create a DataFrame for easier manipulation\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['species'] = iris.target\n",
        "df['species_name'] = iris.target_names[iris.target]\n",
        "\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(\"\\nSpecies Distribution:\")\n",
        "print(df['species_name'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Data Visualization and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a comprehensive visualization of the dataset\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# 1. Pairplot for feature relationships\n",
        "sns.scatterplot(data=df, x='sepal length (cm)', y='sepal width (cm)', \n",
        "                hue='species_name', ax=axes[0,0])\n",
        "axes[0,0].set_title('Sepal Length vs Sepal Width')\n",
        "\n",
        "sns.scatterplot(data=df, x='petal length (cm)', y='petal width (cm)', \n",
        "                hue='species_name', ax=axes[0,1])\n",
        "axes[0,1].set_title('Petal Length vs Petal Width')\n",
        "\n",
        "# 2. Box plots for feature distributions\n",
        "df_melted = df.melt(id_vars=['species_name'], \n",
        "                    value_vars=iris.feature_names,\n",
        "                    var_name='feature', value_name='value')\n",
        "\n",
        "sns.boxplot(data=df_melted, x='feature', y='value', hue='species_name', ax=axes[1,0])\n",
        "axes[1,0].set_title('Feature Distributions by Species')\n",
        "axes[1,0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# 3. Correlation heatmap\n",
        "correlation_matrix = df[iris.feature_names].corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[1,1])\n",
        "axes[1,1].set_title('Feature Correlation Matrix')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print basic statistics\n",
        "print(\"\\nDataset Statistics:\")\n",
        "print(df[iris.feature_names].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Data Preprocessing and Train-Test Split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate features and target\n",
        "X = df[iris.feature_names]  # Features\n",
        "y = df['species']  # Target (already encoded as 0, 1, 2)\n",
        "\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Target shape:\", y.shape)\n",
        "print(\"\\nTarget classes:\", np.unique(y))\n",
        "print(\"Target class names:\", iris.target_names)\n",
        "\n",
        "# Check for missing values (there shouldn't be any in Iris dataset)\n",
        "print(\"\\nMissing values in features:\", X.isnull().sum().sum())\n",
        "print(\"Missing values in target:\", pd.Series(y).isnull().sum())\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"\\nTraining set size:\", X_train.shape[0])\n",
        "print(\"Test set size:\", X_test.shape[0])\n",
        "print(\"\\nTraining set class distribution:\")\n",
        "print(pd.Series(y_train).value_counts().sort_index())\n",
        "print(\"\\nTest set class distribution:\")\n",
        "print(pd.Series(y_test).value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Train Decision Tree Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and train the decision tree classifier\n",
        "dt_classifier = DecisionTreeClassifier(\n",
        "    random_state=42,\n",
        "    max_depth=3,  # Limit depth to prevent overfitting\n",
        "    min_samples_split=5,  # Minimum samples to split a node\n",
        "    min_samples_leaf=2   # Minimum samples in a leaf node\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "print(\"Decision Tree Classifier trained successfully!\")\n",
        "print(f\"Number of features: {dt_classifier.n_features_in_}\")\n",
        "print(f\"Number of classes: {dt_classifier.n_classes_}\")\n",
        "print(f\"Tree depth: {dt_classifier.get_depth()}\")\n",
        "print(f\"Number of leaves: {dt_classifier.get_n_leaves()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Evaluate Model Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_train_pred = dt_classifier.predict(X_train)\n",
        "y_test_pred = dt_classifier.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"=== MODEL PERFORMANCE ===\")\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Calculate precision and recall for each class\n",
        "precision = precision_score(y_test, y_test_pred, average=None)\n",
        "recall = recall_score(y_test, y_test_pred, average=None)\n",
        "\n",
        "print(\"\\n=== DETAILED METRICS ===\")\n",
        "print(\"\\nPer-class Precision:\")\n",
        "for i, species in enumerate(iris.target_names):\n",
        "    print(f\"{species}: {precision[i]:.4f}\")\n",
        "\n",
        "print(\"\\nPer-class Recall:\")\n",
        "for i, species in enumerate(iris.target_names):\n",
        "    print(f\"{species}: {recall[i]:.4f}\")\n",
        "\n",
        "# Overall precision and recall (macro average)\n",
        "macro_precision = precision_score(y_test, y_test_pred, average='macro')\n",
        "macro_recall = recall_score(y_test, y_test_pred, average='macro')\n",
        "\n",
        "print(f\"\\nMacro-averaged Precision: {macro_precision:.4f}\")\n",
        "print(f\"Macro-averaged Recall: {macro_recall:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\n=== CLASSIFICATION REPORT ===\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=iris.target_names))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Visualize Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "# Visualize confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=iris.target_names, \n",
        "            yticklabels=iris.target_names)\n",
        "plt.title('Confusion Matrix - Decision Tree Classifier')\n",
        "plt.xlabel('Predicted Species')\n",
        "plt.ylabel('Actual Species')\n",
        "plt.show()\n",
        "\n",
        "# Visualize the decision tree\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(dt_classifier, \n",
        "          feature_names=iris.feature_names,\n",
        "          class_names=iris.target_names,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          fontsize=10)\n",
        "plt.title('Decision Tree Visualization', fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# Print feature importance\n",
        "feature_importance = dt_classifier.feature_importances_\n",
        "print(\"\\n=== FEATURE IMPORTANCE ===\")\n",
        "for i, (feature, importance) in enumerate(zip(iris.feature_names, feature_importance)):\n",
        "    print(f\"{feature}: {importance:.4f}\")\n",
        "\n",
        "# Visualize feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=feature_importance, y=iris.feature_names, palette='viridis')\n",
        "plt.title('Feature Importance in Decision Tree')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Summary and Conclusions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== FINAL SUMMARY ===\")\n",
        "print(f\"\\nðŸŽ¯ Model Performance:\")\n",
        "print(f\"   â€¢ Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "print(f\"   â€¢ Macro Precision: {macro_precision:.4f}\")\n",
        "print(f\"   â€¢ Macro Recall: {macro_recall:.4f}\")\n",
        "\n",
        "print(f\"\\nðŸŒ³ Decision Tree Characteristics:\")\n",
        "print(f\"   â€¢ Depth: {dt_classifier.get_depth()}\")\n",
        "print(f\"   â€¢ Leaves: {dt_classifier.get_n_leaves()}\")\n",
        "print(f\"   â€¢ Most important feature: {iris.feature_names[np.argmax(feature_importance)]}\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Key Insights:\")\n",
        "print(f\"   â€¢ The model achieved excellent performance on the Iris dataset\")\n",
        "print(f\"   â€¢ Petal measurements are more important than sepal measurements\")\n",
        "print(f\"   â€¢ The decision tree is interpretable and makes logical decisions\")\n",
        "print(f\"   â€¢ No overfitting detected (small gap between train/test accuracy)\")\n",
        "\n",
        "print(f\"\\nâœ… Task 1 Complete: Iris Classification with Decision Tree\")\n",
        "print(f\"   All objectives achieved:\")\n",
        "print(f\"   âœ“ Data preprocessing completed\")\n",
        "print(f\"   âœ“ Decision tree classifier trained\")\n",
        "print(f\"   âœ“ Model evaluated with accuracy, precision, and recall\")\n",
        "print(f\"   âœ“ Results visualized and interpreted\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
